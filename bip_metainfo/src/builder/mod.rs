use std::iter::ExactSizeIterator;

use bip_bencode::{BMutAccess, BRefAccess, BencodeMut};
use bip_util::sha::{self, ShaHash};

use crate::accessor::{Accessor, IntoAccessor};
use crate::error::ParseResult;
use crate::parse;

mod buffer;
mod worker;

// Piece length is inversly related to the file size.
// Transfer reliability is inversly related to the piece length.
// Transfer reliability is directly related to the file size.

// These statements hold even today, although the piece lengths that were historically
// recommended may be out of date as we get faster and more reliable network speeds.

// So for balanced, file size, and transfer piece length optimizations, calculate the
// minimum piece length we can do to reach the designated pieces size. Then, if that
// piece length is less than the minimum piece length for that optimization, set it equal
// to the minimum. Setting it equal to the minimum (in that case) will increase the piece
// size which will shrink the pieces size which ensures we do not go outside of our max size.
// This ensure we can generate good piece lengths for both large and small files.

// Maximum Piece Length Across The Board, Takes Priority Over Max Pieces Sizes
// (Not Applied To Custom Lengths)
const ALL_OPT_MAX_PIECE_LENGTH: usize = 16 * 1024 * 1024;

const BALANCED_MAX_PIECES_SIZE: usize = 40000;
const BALANCED_MIN_PIECE_LENGTH: usize = 512 * 1024;

const FILE_SIZE_MAX_PIECES_SIZE: usize = 20000;
const FILE_SIZE_MIN_PIECE_LENGTH: usize = 1 * 1024 * 1024;

const TRANSFER_MAX_PIECES_SIZE: usize = 60000;
const TRANSFER_MIN_PIECE_LENGTH: usize = 1 * 1024;

/// Enumerates settings for piece length for generating a torrent file.
pub enum PieceLength {
    /// Optimize piece length for torrent file size and file transfer.
    OptBalanced,
    /// Optimize piece length for torrent file size.
    OptFileSize,
    /// Optimize piece length for torrent file transfer.
    OptTransfer,
    /// Custom piece length.
    Custom(usize),
}

/// Builder for generating a torrent file from some accessor.
pub struct MetainfoBuilder<'a> {
    root: BencodeMut<'a>,
    info: InfoBuilder<'a>,
}

impl<'a> MetainfoBuilder<'a> {
    /// Create a new MetainfoBuilder with some default values set.
    pub fn new() -> MetainfoBuilder<'a> {
        MetainfoBuilder {
            root: BencodeMut::new_dict(),
            info: InfoBuilder::new(),
        }
    }

    /// Set announce-list content
    pub fn set_trackers(mut self, opt_trackers: Option<&'a Vec<Vec<String>>>) -> MetainfoBuilder<'a> {
        {
            let dict_access = self.root.dict_mut().unwrap();

            if let Some(groups) = opt_trackers {
                let mut list = BencodeMut::new_list();

                {
                    let list_access = list.list_mut().unwrap();

                    for group in groups.iter() {
                        let mut tracker_list = BencodeMut::new_list();

                        {
                            let tracker_list_access = tracker_list.list_mut().unwrap();

                            for tracker_url in group.iter() {
                                tracker_list_access.push(ben_bytes!(&tracker_url[..]));
                            }
                        }

                        list_access.push(tracker_list);
                    }
                }

                dict_access.insert(parse::ANNOUNCE_LIST_KEY.into(), list);
            } else {
                dict_access.remove(parse::ANNOUNCE_LIST_KEY);
            }
        }

        self
    }

    /// Set or unset the main tracker that this torrent file points to.
    pub fn set_main_tracker(mut self, opt_tracker_url: Option<&'a str>) -> MetainfoBuilder<'a> {
        {
            let dict_access = self.root.dict_mut().unwrap();

            if let Some(tracker_url) = opt_tracker_url {
                dict_access.insert(parse::ANNOUNCE_URL_KEY.into(), ben_bytes!(tracker_url));
            } else {
                dict_access.remove(parse::ANNOUNCE_URL_KEY);
            }
        }

        self
    }

    /// Set or unset the creation date for the torrent.
    pub fn set_creation_date(mut self, opt_secs_epoch: Option<i64>) -> MetainfoBuilder<'a> {
        {
            let dict_access = self.root.dict_mut().unwrap();

            if let Some(secs_epoch) = opt_secs_epoch {
                dict_access.insert(parse::CREATION_DATE_KEY.into(), ben_int!(secs_epoch));
            } else {
                dict_access.remove(parse::CREATION_DATE_KEY);
            }
        }

        self
    }

    /// Set or unset a comment for the torrent file.
    pub fn set_comment(mut self, opt_comment: Option<&'a str>) -> MetainfoBuilder<'a> {
        {
            let dict_access = self.root.dict_mut().unwrap();

            if let Some(comment) = opt_comment {
                dict_access.insert(parse::COMMENT_KEY.into(), ben_bytes!(comment));
            } else {
                dict_access.remove(parse::COMMENT_KEY);
            }
        }

        self
    }

    /// Set or unset the created by for the torrent file.
    pub fn set_created_by(mut self, opt_created_by: Option<&'a str>) -> MetainfoBuilder<'a> {
        {
            let dict_access = self.root.dict_mut().unwrap();

            if let Some(created_by) = opt_created_by {
                dict_access.insert(parse::CREATED_BY_KEY.into(), ben_bytes!(created_by));
            } else {
                dict_access.remove(parse::CREATED_BY_KEY);
            }
        }

        self
    }

    /// Set or unset the private flag for the torrent file.
    pub fn set_private_flag(mut self, opt_is_private: Option<bool>) -> MetainfoBuilder<'a> {
        self.info = self.info.set_private_flag(opt_is_private);

        self
    }

    /// Sets the piece length for the torrent file.
    pub fn set_piece_length(mut self, piece_length: PieceLength) -> MetainfoBuilder<'a> {
        self.info = self.info.set_piece_length(piece_length);

        self
    }

    /// Get decoded value of announce-list key
    pub fn get_trackers(&self) -> Option<Vec<Vec<String>>> {
        let dict_access = self.root.dict().unwrap();

        parse::parse_announce_list(dict_access).map(parse::convert_announce_list)
    }

    /// Get decoded value of announce-url key
    pub fn get_main_tracker(&self) -> Option<String> {
        let dict_access = self.root.dict().unwrap();

        parse::parse_announce_url(dict_access).map(String::from)
    }

    /// Get decoded value of creation-date key
    pub fn get_creation_date(&self) -> Option<i64> {
        let dict_access = self.root.dict().unwrap();

        parse::parse_creation_date(dict_access)
    }

    /// Get decoded value of comment key
    pub fn get_comment(&self) -> Option<String> {
        let dict_access = self.root.dict().unwrap();

        parse::parse_comment(dict_access).map(String::from)
    }

    /// Get decoded value of created-by key
    pub fn get_created_by(&self) -> Option<String> {
        let dict_access = self.root.dict().unwrap();

        parse::parse_created_by(dict_access).map(String::from)
    }

    /// Build the metainfo file from the given accessor and the number of worker threads.
    ///
    /// Panics if threads is equal to zero.
    pub fn build<A, C>(self, threads: usize, accessor: A, progress: C) -> ParseResult<Vec<u8>>
    where
        A: IntoAccessor,
        C: FnMut(f64) + Send + 'static,
    {
        let accessor = accessor.into_accessor()?;

        build_with_accessor(threads, accessor, progress, Some(self.root), self.info.info, self.info.piece_length)
    }
}

// ----------------------------------------------------------------------------//

/// Builder for generating an info dictionary file from some accessor.
pub struct InfoBuilder<'a> {
    info: BencodeMut<'a>,
    // Stored outside of root as some of the variants need the total
    // file sizes in order for the final piece length to be calculated.
    piece_length: PieceLength,
}

impl<'a> InfoBuilder<'a> {
    pub fn new() -> InfoBuilder<'a> {
        InfoBuilder {
            info: BencodeMut::new_dict(),
            piece_length: PieceLength::OptBalanced,
        }
    }

    /// Set or unset the private flag for the torrent file.
    pub fn set_private_flag(mut self, opt_is_private: Option<bool>) -> InfoBuilder<'a> {
        let opt_numeric_is_private = opt_is_private.map(|is_private| if is_private { 1 } else { 0 });

        {
            let dict_access = self.info.dict_mut().unwrap();
            opt_numeric_is_private
                .and_then(|numeric_is_private| dict_access.insert(parse::PRIVATE_KEY.into(), ben_int!(numeric_is_private)))
                .or_else(|| dict_access.remove(parse::PRIVATE_KEY));
        }

        self
    }

    /// Sets the piece length for the torrent file.
    pub fn set_piece_length(mut self, piece_length: PieceLength) -> InfoBuilder<'a> {
        self.piece_length = piece_length;

        self
    }

    /// Build the metainfo file from the given accessor and the number of worker threads.
    ///
    /// Panics if threads is equal to zero.
    pub fn build<A, C>(self, threads: usize, accessor: A, progress: C) -> ParseResult<Vec<u8>>
    where
        A: IntoAccessor,
        C: FnMut(f64) + Send + 'static,
    {
        let accessor = accessor.into_accessor()?;

        build_with_accessor(threads, accessor, progress, None, self.info, self.piece_length)
    }
}

// ----------------------------------------------------------------------------//

fn build_with_accessor<'a, A, C>(
    threads: usize,
    accessor: A,
    progress: C,
    opt_root: Option<BencodeMut<'a>>,
    info: BencodeMut<'a>,
    piece_length: PieceLength,
) -> ParseResult<Vec<u8>>
where
    A: Accessor,
    C: FnMut(f64) + Send + 'static,
{
    if threads == 0 {
        panic!("bip_metainfo: Cannot Build Metainfo File With threads == 0");
    }

    // Collect all of the file information into a list
    let mut files_info = Vec::new();
    accessor.access_metadata(|len, path| {
        let path_list: Vec<String> = path.iter().map(|os_str| os_str.to_string_lossy().into_owned()).collect();

        files_info.push((len, path_list));
    })?;

    // Build the pieces for the data our accessor is pointing at
    let total_files_len = files_info.iter().fold(0, |acc, nex| acc + nex.0);
    let piece_length = determine_piece_length(total_files_len, piece_length);
    let total_num_pieces = ((total_files_len as f64) / (piece_length as f64)).ceil() as u64;
    let pieces_list = worker::start_hasher_workers(&accessor, piece_length, total_num_pieces, threads, progress)?;
    let pieces = map_pieces_list(pieces_list.into_iter().map(|(_, piece)| piece));

    let mut single_file_name = String::new();
    let access_directory = accessor.access_directory().map(|path| path.to_string_lossy());

    // Move these below access directory for borrow checker
    let opt_root = opt_root;
    let mut info = info;

    // Update the info bencode with values
    {
        let info_access = info.dict_mut().unwrap();

        info_access.insert(parse::PIECE_LENGTH_KEY.into(), ben_int!(piece_length as i64));
        info_access.insert(parse::PIECES_KEY.into(), ben_bytes!(&pieces[..]));

        // If the accessor specifies a directory OR there are mutliple files, we will build a multi file torrent
        // If the directory is not present but there are multiple files, the direcotry field will be set to empty
        match (&access_directory, files_info.len() > 1) {
            (&Some(ref directory), _) => {
                let mut bencode_files = BencodeMut::new_list();

                {
                    let bencode_files_access = bencode_files.list_mut().unwrap();

                    // Multi File
                    for &(len, ref path) in files_info.iter() {
                        let mut bencode_path = BencodeMut::new_list();

                        {
                            let bencode_path_access = bencode_path.list_mut().unwrap();

                            for path_element in path.iter() {
                                bencode_path_access.push(ben_bytes!(&path_element[..]));
                            }
                        }

                        bencode_files_access.push(ben_map! {
                            parse::LENGTH_KEY => ben_int!(len as i64),
                            parse::PATH_KEY   => bencode_path
                        });
                    }
                }

                info_access.insert(parse::NAME_KEY.into(), ben_bytes!(directory.as_ref()));
                info_access.insert(parse::FILES_KEY.into(), bencode_files);
            },
            (&None, true) => {
                let mut bencode_files = BencodeMut::new_list();

                {
                    let bencode_files_access = bencode_files.list_mut().unwrap();

                    // Multi File
                    for &(len, ref path) in files_info.iter() {
                        let mut bencode_path = BencodeMut::new_list();

                        {
                            let bencode_path_access = bencode_path.list_mut().unwrap();

                            for path_element in path.iter() {
                                bencode_path_access.push(ben_bytes!(&path_element[..]));
                            }
                        }

                        bencode_files_access.push(ben_map! {
                            parse::LENGTH_KEY => ben_int!(len as i64),
                            parse::PATH_KEY   => bencode_path
                        });
                    }
                }

                info_access.insert(parse::NAME_KEY.into(), ben_bytes!(""));
                info_access.insert(parse::FILES_KEY.into(), bencode_files);
            },
            (&None, false) => {
                // Single File
                for name_component in files_info[0].1.iter() {
                    single_file_name.push_str(name_component);
                }

                info_access.insert(parse::LENGTH_KEY.into(), ben_int!(files_info[0].0 as i64));
                info_access.insert(parse::NAME_KEY.into(), ben_bytes!(&single_file_name[..]));
            },
        }
    }

    if let Some(mut root) = opt_root {
        root.dict_mut().unwrap().insert(parse::INFO_KEY.into(), info);

        Ok(root.encode())
    } else {
        Ok(info.encode())
    }
}

/// Calculate the final piece length given the total file size and piece length strategy.
///
/// Lower piece length will result in a bigger file but better transfer reliability and vice versa.
fn determine_piece_length(total_file_size: u64, piece_length: PieceLength) -> usize {
    match piece_length {
        PieceLength::Custom(len) => len,
        PieceLength::OptBalanced => calculate_piece_length(total_file_size, BALANCED_MAX_PIECES_SIZE, BALANCED_MIN_PIECE_LENGTH),
        PieceLength::OptFileSize => calculate_piece_length(total_file_size, FILE_SIZE_MAX_PIECES_SIZE, FILE_SIZE_MIN_PIECE_LENGTH),
        PieceLength::OptTransfer => calculate_piece_length(total_file_size, TRANSFER_MAX_PIECES_SIZE, TRANSFER_MIN_PIECE_LENGTH),
    }
}

/// Calculate the minimum power of 2 piece length for the given max pieces size and total file size.
fn calculate_piece_length(total_file_size: u64, max_pieces_size: usize, min_piece_length: usize) -> usize {
    let num_pieces = (max_pieces_size as f64) / (sha::SHA_HASH_LEN as f64);
    let piece_length = ((total_file_size as f64) / num_pieces + 0.5) as usize;

    let pot_piece_length = piece_length.next_power_of_two();

    match (pot_piece_length > min_piece_length, pot_piece_length < ALL_OPT_MAX_PIECE_LENGTH) {
        (true, true) => pot_piece_length,
        (false, _) => min_piece_length,
        (_, false) => ALL_OPT_MAX_PIECE_LENGTH,
    }
}
/// Map the pieces list into a list of bytes (byte string).
fn map_pieces_list<I>(pieces: I) -> Vec<u8>
where
    I: Iterator<Item = ShaHash> + ExactSizeIterator,
{
    let mut concated_pieces = Vec::with_capacity(pieces.len() * sha::SHA_HASH_LEN);
    for piece in pieces {
        concated_pieces.extend_from_slice(piece.as_ref());
    }

    concated_pieces
}
